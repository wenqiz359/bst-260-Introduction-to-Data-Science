ggplot(aes(log10(population), log10(total))) +
geom_point()
grid.arrange(p1, p2, ncol = 2)
library(tidyverse)
library(dslabs)
path <- system.file("extdata", package = "dslabs")
filename <- file.path(path, "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)
select(wide_data, 1:10)
p1 <- dat |> ggplot(aes(year, fertility, color = country)) + geom_line(show.legend = FALSE)
p2 <- dat |> ggplot(aes(year, life_expectancy, color = country)) + geom_line()
gridExtra::grid.arrange(p1, p2, ncol = 2, widths = c(3,4))
gridExtra
library(gridExtra)
gridExtra
gridExtra::grid.arrange
?grid.arrange
file.copy(file_path, "murders.csv")
dir <- system.file(package = "dslabs")
file_path <- file.path(dir, "extdata/murders.csv")
file.copy(file_path, "murders.csv")
file.copy
?file.copy
file_path
file.copy(file_path, "murders.csv")
dir <- system.file(package = "dslabs")
file_path <- file.path(dir, "extdata/murders.csv")
file.copy(file_path, "murders.csv")
readLines("murders.csv", n = 3)
#binary files
#
```{r}
x <- read.table("murders.csv", sep = "\t")
x
x <- read.csv("murders.csv")
x
x <- read_delim("murders.csv", delim = "\t")
x
library(readr)
x <- read_delim("murders.csv", delim = "\t")
x
x <- read_delim("murders.csv", delim = ",")
x
y <- read_xls(fn)
library(readxl)
fn <- file.path(dir, "extdata/2010_bigfive_regents.xls")
y <- read_xls(fn)
y
x <- fread("murders.csv")
library(data.table)
x <- fread("murders.csv")
x
scan("murders.csv", what = "c", sep = ",", n = 10)
dates
library(lubridate)
set.seed(2002)
dates <- sample(polls_us_election_2016$startdate, 10) |> sort()
dates
ymd(x)
library(lubridate)
set.seed(2002)
dates <- sample(polls_us_election_2016$startdate, 10) |> sort()
dates
tibble(date = dates, month = month(dates), day = day(dates), year = year(dates))
month(dates, label = TRUE)
library(lubridate)
set.seed(2002)
dates <- sample(polls_us_election_2016$startdate, 10) |> sort()
dates
tibble(date = dates, month = month(dates), day = day(dates), year = year(dates))
month(dates, label = TRUE)
month(dates,label = TRUE)
tibble(date = dates, month = month(dates), day = day(dates), year = year(dates))
x <- c(20090101, "2009-01-02", "2009 01 03", "2009-1-4",
"2009-1, 5", "Created on 2009 1 6", "200901 !!! 07")
ymd(x)
system("locale -a")
locale(date_names = "es")
dat
parse_date(dat$f.n., format = "%d de %B de %Y", locale = locale(date_names = "es"))
dat$f.n.
dat
parse_date(dat$f.n., format = "%d de %B de %Y", locale = locale(date_names = "es"))
library(jsonlite)
nobel <- fromJSON("http://api.nobelprize.org/v1/prize.json")
nobel
nobel <- fromJSON("http://api.nobelprize.org/v1/prize.json"ï¼ŒsimplifyDataFrame=TRUE)
nobel <- fromJSON("http://api.nobelprize.org/v1/prize.json",simplifyDataFrame=TRUE)
nobel
url <- "https://data.cdc.gov/resource/muzy-jte6.csv"
response <- request(url)
response <- request(url) <- req_perform()
response <- request(url) <- req_perform(url)
response <- request(url) |> req_perform(url)
response <- request(url) |> req_perform()
response
tab <- response |>resp_body_string() |> read_csv()
tab
tab <- response |>resp_body_string()
tab
tab <- response |>resp_body_json() |> read_csv()
tab <- response |>resp_body_json()
response
tab <- response |>resp_body_string() |> read_csv()
?api
?req_url_path_append
response <- request(url) |> req_url_path_append("?$limit=100000")
response
response <- request(url) |> req_url_path_append("?$limit=100000")|>
req_perform()
response
tab <- response(url)|> req_perform()|> resp_body_json()|> read_json()
tab <- request(url)|> req_perform()|> resp_body_json()|> read_json()
tab <- request(url)|> req_perform()
tab
url <- "https://data.cdc.gov/resource/muzy-jte6.json"
tab <- request(url)|> req_perform()|> resp_body_json()|> read_json()
url <- "https://data.cdc.gov/resource/muzy-jte6.json"
tab <- request(url)|> req_perform()|> resp_body_json()
tab
tab <- request(url)|> req_perform()|> resp_body_json(simplifyDataFrame = TRUE)
tab
library(rvest)
h <- read_html(url)
h
class(h)
html_text(h)
class="wikitable sortable">
```
html_text(h)
<table class="wikitable sortable">
html_text(h)
html_text(h)
#html_text(h)
html_nodes(h)
h <- read_html(url)
#html_text(h)
html_nodes(h)
#html_text(h)
html_nodes(url)
#html_text(h)
html_node(url)
#html_text(h)
tab <- h |> html_nodes("table")
tab
h <- read_html(url)
h <- read_html(url)
class(h)
class(h)
#html_text(h)
tab <- h |> html_nodes("table")
library(rvest)
h <- read_html(url)
class(h)
#html_text(h)
tab <- h |> html_nodes("table")
tab
#html_text(h)
tab <- h |> html_nodes("table")
tab
url <- paste0("https://en.wikipedia.org/w/index.php?title=",
"Gun_violence_in_the_United_States_by_state",
"&direction=prev&oldid=810166167")
library(rvest)
h <- read_html(url)
class(h)
#html_text(h)
tab <- h |> html_nodes("table")
tab
class(tab)
tab[1]
tab[[1]]
tab[1]
tab[[1]]
tab[[1]]|> html_table()
tab
tab <- tab|>
setNames(c("state", "population", "total", "murder_rate")) |>
mutate(across(c(population, total), parse_number))|>
head()
tab
tab <- tab[[1]]|> html_table()
tab <- tab|>
setNames(c("state", "population", "total", "murder_rate")) |>
mutate(across(c(population, total), parse_number))|>
head()
tab
tab <- h |> html_nodes("table")
tab <- tab[[1]]|> html_table()
tab
tab <- tab|>
setNames(c("state", "population", "total", "murder_rate"))
tab
tab <- tab|>
setNames(c("state", "population", "total", "murder_rate")) |>
mutate(across(c(population, total), parse_number))|>
head()
tab
slice(murders, 1:6)
slice(murders, 1:6)
tab_1 <- slice(murders, 1:6) |> select(state, population)
tab_2 <- results_us_election_2016 |>
filter(state %in% c("Alabama", "Alaska", "Arizona",
"California", "Connecticut", "Delaware")) |>
select(state, electoral_votes) |> rename(ev = electoral_votes)
#The semi_join function lets us keep the part of first table for which we have information in the second.
#It does not add the columns of the second:
semi_join(tab_1, tab_2, by = "state")
anti_join(tab_1, tab_2, by = "state")
#| message: false
library(dplyr)
library(tidyr)
library(forcats)
library(ggplot2)
library(knitr)
library(NHANES)
options(digits = 2)
dat <- filter(NHANES,SurveyYr=='2011_12')
dat |>
group_by(Gender) |>
summarize(avg = mean(BPSysAve,na.rm = TRUE),
sd = sd(BPSysAve,na.rm = TRUE)) |>
kable()
dat |> group_by(Gender, Race3) |>
summarize(avg = mean(BPSysAve,na.rm = TRUE),
sd = sd(BPSysAve,na.rm = TRUE)) |>
ungroup()|>
arrange(Gender, desc(avg)) |>
kable()
dat |> group_by(Gender,Race3) |>
filter(!is.na(BPSysAve)) |>
summarize(avg = mean(BPSysAve),
sd = sd(BPSysAve),
n = n()) |>
ungroup() |>
mutate(lower = avg - 1.96 * sd / sqrt(n),
upper = avg + 1.96 * sd / sqrt(n))|>
kable()
dat |> group_by(Gender,Race3) |>
filter(!is.na(BPSysAve)) |>
summarize(avg = mean(BPSysAve),
sd = sd(BPSysAve),
n = n()) |>
ungroup() |>
mutate(lower = avg - 1.96 * sd / sqrt(n),
upper = avg + 1.96 * sd / sqrt(n)) |>
ggplot(aes(x = reorder(Race3,avg), y = avg, col=Gender)) +
geom_point(size =2) +
geom_errorbar(aes(ymin = lower, ymax = upper))+
facet_wrap(~ Gender) +
labs(
title = "Comparing Systolic Blood Pressure Across Groups",
x = "Race",
y = "Average",
caption = "Bars represent 95% confidence intervals"
) +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
dat |>
filter(!is.na(AgeDecade), !is.na(BPSysAve)) |>
group_by(Gender,AgeDecade) |>
summarize(avg = mean(BPSysAve)) |>
arrange(AgeDecade)|>
ggplot(aes(x = AgeDecade, y = avg, col=Gender)) +
geom_point(size =2) +
facet_wrap(~ Gender) +
labs(
title = "Comparing Systolic Blood Pressure Across Groups",
x = "Age Decade",
y = "Average"
) +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
dat |> group_by(Gender, Race3, Age) |>
filter(!is.na(Age)) |>
arrange(Gender, Age) |>
ggplot(aes(x = Age, color = Gender)) +
geom_histogram(aes(y = after_stat(density)),binwidth = 5, boundary = 0)+
facet_grid(Race3 ~ Gender)+
labs(x = "Age",
y = "Density",
title = "Density Across Groups") +
theme(
plot.title = element_text(hjust = 0.5),
)
dat |> group_by(Race3) |>
summarise(median_age=median(Age),
under_18_percent = mean(Age <18)*100) |>
arrange(median_age)|>
kable()
dat |> filter(!is.na(BPSysAve),!is.na(AgeDecade))|>
group_by(Gender, AgeDecade, Race3) |>
summarize(count = n()) |>
ungroup()|>
complete(Gender, Race3, AgeDecade,fill = list(count = 0)) |>
filter(count < 5)|>
kable()
dat <- NHANES |>
filter(SurveyYr == '2011_12',
!is.na(AgeDecade),
AgeDecade != ' 0-9',
Race3 != 'Other')|>
mutate(AgeDecade = fct_collapse(AgeDecade,
" 60+" = c(" 60-69", " 70+"))) |>
rename(Race = Race3)
dat |>
filter(!is.na(AgeDecade), !is.na(BPSysAve)) |>
group_by(AgeDecade,Gender,Race) |>
summarize(avg = mean(BPSysAve)) |>
arrange(AgeDecade)|>
ggplot(aes(x = AgeDecade,y=avg, color = Race,group =Race)) +
geom_line() +
geom_point()+
facet_wrap(~Gender, scales = "free_y") +
labs(
title = "Comparing Systolic Blood Pressure Across Groups",
x = "AgeDecade",
y = "Average"
) +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
dat |>
filter(!is.na(AgeDecade),
!is.na(BPSysAve),
Race %in% c("White", "Black")) |>
group_by(AgeDecade,Gender,Race) |>
summarize(avg = mean(BPSysAve),
sd = sd(BPSysAve),
n = n()) |>
ungroup() |>
mutate(lower = avg - 1.96 * sd / sqrt(n),
upper = avg + 1.96 * sd / sqrt(n)) |>
ggplot(aes(x = AgeDecade,y=avg, color = Race,group =Race)) +
geom_point(size =2) +
geom_errorbar(aes(ymin = lower, ymax = upper))+
facet_wrap(~Gender, scales = "free_y") +
labs(
title = "Comparing Systolic Blood Pressure Across Groups",
x = "AgeDecade",
y = "Average"
) +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
dat |>
filter(!is.na(AgeDecade),
!is.na(BPSysAve),
Race %in% c("White", "Black")) |>
group_by(AgeDecade,Gender,Race) |>
summarize(avg = mean(BPSysAve)) |>
ungroup() |>
pivot_wider(
names_from = c(Gender,Race),
values_from = avg
)|>
mutate(diff_females = female_Black-female_White,
diff_males = male_Black-male_White) |>
select(AgeDecade,diff_females,diff_males)|>
kable()
dat$Age<18
mean(dat$Age<18)
dat |> group_by(Race3) |>
summarise(median_age=median(Age),
under_18_percent = mean(Age <18)*100) |>
arrange(median_age)|>
kable()
dat |> filter(!is.na(BPSysAve),!is.na(AgeDecade))|>
group_by(Gender, AgeDecade, Race3) |>
summarize(count = n()) |>
ungroup()|>
complete(Gender, Race3, AgeDecade,fill = list(count = 0)) |>
filter(count < 5)|>
kable()
source('census-key.R')
url <- "https://api.census.gov/data/2021/pep/population"
#| message: false
#| warning: false
library(httr2)
request <- request(url) |> req_url_query(get = I("POP_2020,POP_2021,NAME"),
`for` = I("state:*"),
key = census_key)
response <- request |> req_perform()
library('httr2')
request |> req_perform() |> resp_content_type()
library(dplyr)
library(janitor)
library(tidyr)
library(stringr)
population <- response |> resp_body_json(simplifyVector = TRUE)
#| message: false
#| warning: false
library(tidyverse)
library(janitor)
population <- population |>
row_to_names(1)|>
as_tibble()|>
select(-state)|>
rename(state_name=NAME) |>
pivot_longer(-state_name, names_to = 'year',values_to ='population')|>
mutate(year = str_remove(year,"POP_"))|>
mutate(across(-state_name,as.numeric))|>
mutate(state= state.abb[match(state_name,state.name)]) |>
mutate(state = case_when (state_name == "Puerto Rico" ~ "PR",
state_name == "District of Columbia" ~ "DC",
.default = state))
head(population)
#population <- population |> ## Use janitor row to names function
# convert to tibble
# remove stat column
# rename state column to state_name
# use pivot_longer to tidy
# remove POP_ from year
# parese all relevant colunns to numeric
# add state abbreviations using state.abb variable
# use case_when to add abbreviations for DC and PR
population |>
ggplot(aes(x = reorder(state_name, population), y = population))+
geom_col(fill='darkblue') +
coord_flip()+
facet_wrap(~year)+
labs(x = "State", y = "Population")
# population |>
# reorder state
# assign aesthetic mapping
# use geom_col to plot barplot
# flip coordinates
# facet by year
url <- "https://github.com/datasciencelabs/2024/raw/refs/heads/main/data/regions.json"
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
regions <- fromJSON(url,simplifyDataFrame = FALSE)
regions <- map_df(regions, function(x)
data.frame(region = x$region, region_name = x$region_name, state_name = x$states)) |>
mutate(region_name = ifelse(region_name == "New York and New Jersey, Puerto Rico, Virgin Islands", "NY & NJ, PR, VI", region_name))
head(regions)
# regions <- use jsonlit JSON parser
# regions <- convert list to data frame. You can use map_df in purrr package
population <- left_join(population, regions, by ="state_name")
head(population)
api <- "https://data.cdc.gov/resource/pwn4-m3yp.json"
cases_raw <- request(api) |> req_perform() |> resp_body_json(simplifyVector = TRUE)
head(cases_raw)
api <- "https://data.cdc.gov/resource/pwn4-m3yp.json?$limit=10000000000"
cases_raw <- request(api) |> req_perform() |> resp_body_json(simplifyVector = TRUE)
cases <- cases_raw|>
mutate(date = as.Date(end_date),cases = as.numeric(new_cases))|>
select(state, date, cases  )
cases|> filter(year(date) %in% c(2020, 2021))|>
mutate(year = year(date))|>
left_join(population, by =c("state",'year')) |>
mutate(cases_per_100k = (cases / population) * 100000) |>
filter(!is.na(cases_per_100k))|>
ggplot(aes(x = date, y = cases_per_100k, color = state_name))+
geom_line()+
facet_wrap(~region_name) +
theme(axis.text.y = element_text(angle = 0, hjust = 3, vjust = 2)) +
labs(x = "Date",
y = "Cases per 100,000") +  # Labels
theme_minimal()  +  # Use a minimal theme
theme(
panel.spacing = unit(0.1, "lines"),
legend.position = "bottom",
axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
axis.text.y = element_text( size = 8),
legend.key.size = unit(0.2, "cm"),
legend.text = element_text(size = 7)
)
library(dplyr)
library(janitor)
library(tidyr)
library(stringr)
population <- response |> resp_body_json(simplifyVector = TRUE)
population
population |>
row_to_names(1)
population |>
row_to_names(1)|>
as_tibble()|>
select(-state)|>
rename(state_name=NAME)
population |>
row_to_names(1)|>
as_tibble()|>
select(-state)|>
rename(state_name=NAME) |>
pivot_longer(-state_name, names_to = 'year',values_to ='population')
match(state_name,state.name)
match(population$state_name,state.name)
population <- population |>
row_to_names(1)|>
as_tibble()|>
select(-state)|>
rename(state_name=NAME) |>
pivot_longer(-state_name, names_to = 'year',values_to ='population')|>
mutate(year = str_remove(year,"POP_"))|>
mutate(across(-state_name,as.numeric))
match(population$state_name,state.name)
state.abb
regions <- fromJSON(url,simplifyDataFrame = FALSE)
regions
regions <- map_df(regions, function(x)
data.frame(region = x$region, region_name = x$region_name, state_name = x$states))
regions
